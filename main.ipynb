{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focused-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project: p7\n",
    "# submitter: lliu356\n",
    "# partner: none\n",
    "# hours: 4\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import netaddr\n",
    "import copy\n",
    "import os\n",
    "\n",
    "class UserPredictor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = Pipeline([('both',make_column_transformer((OneHotEncoder(),['badge']),\n",
    "                                                               (OneHotEncoder(),['region']),\n",
    "                                                               (PolynomialFeatures(degree = 2,include_bias=False),['weighted_time']),\n",
    "                                                               remainder = \"passthrough\")),\n",
    "                               ('cls', LogisticRegression(fit_intercept=False))])       \n",
    "        self.features_cols = ['region','badge','age','past_purchase_amt','weighted_time']\n",
    "        self.y = 'y'\n",
    "        \n",
    "    def process_raw(self,users,logs, y = None):\n",
    "        ### user:\n",
    "        user_tmp = users #.copy()\n",
    "        \n",
    "        ### logs: match region\n",
    "        ip2check_test = list(logs['ip_address'])\n",
    "        ip_df = self.ip2location_load()\n",
    "        match_region_out = self.ip_check(ip2check_test,ip_df)\n",
    "        logs_add_region = logs #.copy()\n",
    "        logs_add_region['region'] = match_region_out\n",
    "        logs_match_region = logs_add_region[['id','region']].drop_duplicates()\n",
    "        \n",
    "        ### logs: match weigted time \n",
    "        page_type = list(logs['url_visited'])\n",
    "        \n",
    "        ### trnsform url (manually)\n",
    "        url_transform = []\n",
    "        #url_ref = {}\n",
    "        for i in range(0,len(page_type)):\n",
    "            tmp = page_type[i].replace('.html','').replace('/','')\n",
    "            url_transform.append(tmp)\n",
    "            #url_ref[tmp] = url_ref.setdefault(tmp,0) + 1\n",
    "        \n",
    "        # Any better idea than hardcoding these categories...?\n",
    "        laptop = ['laptop']; office = ['tablet','keyboard','monitor','printer','desk']\n",
    "        \n",
    "        ### weight time\n",
    "        page_type = list(logs['url_visited'])\n",
    "        minutes_raw = list(logs['minutes_on_page'])\n",
    "        minutes_weighted = [None] * len(minutes_raw)\n",
    "        \n",
    "        for i in range(0,len(page_type)):\n",
    "            tmp = page_type[i].replace('.html','').replace('/','')\n",
    "            if tmp in laptop:\n",
    "                minutes_weighted[i] = minutes_raw[i] * 0.7\n",
    "            elif tmp in office:\n",
    "                minutes_weighted[i] = minutes_raw[i] * 0.2\n",
    "            else:\n",
    "                minutes_weighted[i] = minutes_raw[i] * 0.1\n",
    "        # extract        \n",
    "        logs_match_weight = logs#.copy()\n",
    "        logs_match_weight['weighted_time'] = minutes_weighted\n",
    "        logs_match_weight = pd.DataFrame(logs_match_weight.groupby('id')['weighted_time'].sum())\n",
    "        \n",
    "        ### merge:\n",
    "        out = pd.merge(pd.merge(user_tmp,logs_match_region,on = 'id'),logs_match_weight,on = 'id')\n",
    "        if not y is None:\n",
    "            out = pd.merge(out, y,on = 'id')\n",
    "            out['y'] = out['y'].map({0:False,1:True})\n",
    "            return out\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def fit(self, train_users, train_logs, train_y, crs_val = False):\n",
    "        \n",
    "        self.features_train = self.process_raw(train_users, train_logs, train_y)\n",
    "        \n",
    "        self.model.fit(self.features_train[self.features_cols],self.features_train[self.y])\n",
    "        \n",
    "        if crs_val:\n",
    "            crs_val_scores  = cross_val_score(self.model,\n",
    "                                              self.features_train[self.features_cols],\n",
    "                                              self.features_train[self.y])\n",
    "            print(f\"AVG: {crs_val_scores.mean()}, STD: {crs_val_scores.std()}\\n\")\n",
    "            \n",
    "    def predict(self,test_users, test_logs):\n",
    "        self.features_test = self.process_raw(test_users, test_logs)\n",
    "        y_predicted = self.model.predict(self.features_test[self.features_cols])\n",
    "                       \n",
    "        return np.asarray(list(map(int, y_predicted)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def BinarySearch(self,arr,x):\n",
    "        left, right = 0, len(arr) - 1\n",
    "        while left < right:\n",
    "            mid = left + (right - left) // 2\n",
    "            if x - arr[mid] > arr[mid + 1] - x:\n",
    "                left = mid + 1\n",
    "            else:\n",
    "                right = mid\n",
    "        if arr[left-1] <= x and arr[left] > x:\n",
    "            return left - 1\n",
    "        else:\n",
    "            return left\n",
    "                       \n",
    "    def ip2location_load(self):\n",
    "        with open(os.path.join('data','ip2location.csv')) as f:\n",
    "            out_raw = f.read()\n",
    "        out = out_raw.split(\"\\n\")\n",
    "        ip_raw = []\n",
    "        for line in out:\n",
    "            line_tmp = line.split(\",\")\n",
    "            ip_raw.append(line_tmp)    \n",
    "        ip_df = pd.DataFrame(ip_raw)\n",
    "        ip_df.rename(columns = ip_df.iloc[0], inplace = True)\n",
    "        ip_df.drop(ip_df.index[0],inplace = True)\n",
    "        ip_df.drop(ip_df.index[-1],inplace = True) # something weird\n",
    "        ip_df.sort_values(by = [\"low\"]) # sort for binary search\n",
    "        ip_df.reset_index(drop = True,inplace = True)\n",
    "        return ip_df\n",
    "    \n",
    "    def ip_check(self,ips,ip_df):\n",
    "        search_sequence = list(map(int, ip_df[\"low\"]))\n",
    "        ip_match_out = []\n",
    "        for ip in ips:    \n",
    "            try:\n",
    "                int_ip = int(netaddr.IPAddress(ip))\n",
    "                index_tmp = self.BinarySearch(search_sequence,int_ip)\n",
    "                matched_region = ip_df.iloc[index_tmp,3]\n",
    "                ip_match_out.append(matched_region)  \n",
    "            except:\n",
    "                print(\"Execution halted...\")\n",
    "                break\n",
    "        return ip_match_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latest-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.8863887221805451, STD: 0.005526936888599186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liheliu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = UserPredictor()\n",
    "train_users = pd.read_csv(\"data/train_users.csv\")\n",
    "train_logs = pd.read_csv(\"data/train_logs.csv\")\n",
    "train_y = pd.read_csv(\"data/train_y.csv\")\n",
    "model.fit(train_users, train_logs, train_y, crs_val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users = pd.read_csv(\"data/test1_users.csv\")\n",
    "test_logs = pd.read_csv(\"data/test1_logs.csv\")\n",
    "y_pred = model.predict(test_users, test_logs)\n",
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
